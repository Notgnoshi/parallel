\documentclass{article}

\input{../homework.sty}

\title{Homework 1}
\author{Austin Gill}

\begin{document}
\maketitle

\section{}
    \begin{quote}
        Recall that OpenMP creates private variables for reduction variables, and these private variables are initialized to the identity element for the reduction operator. For example, if the operator is addition, the private variables are initialized to 0, while if the operator is multiplication, the private variables are initialized to 1.

        What are the identity values for these operators: \mintinline{c}{&&}, \mintinline{c}{||}, \mintinline{c}{|}, and \mintinline{c}{^}?
    \end{quote}

    The mathematical identity for $\land$ is $T$, because $x \land T \equiv x$, thus the identity for the \mintinline{c}{&&} operator is \mintinline{cpp}{true}. Similarly, the identity for the \mintinline{c}{||} operator is \mintinline{cpp}{false}. The identities for the bitwise operations \mintinline{c}{|} and \mintinline{c}{^} are both \mintinline{c}{0x0}.

\section{}
    \begin{quote}
        Suppose OpenMP did not have the \mintinline{c}{reduction} clause. Show how to implement an \textit{efficient} parallel reduction by adding a private variable and using the \mintinline{c}{critical} pragma.
    \end{quote}

    Consider the following three solutions.

    \begin{enumerate}
        \item Normal reduction: \begin{minted}{c}
            size_t sum1 = 0;
            #pragma omp parallel for num_threads( 8 ) reduction(+:sum1)
            for( size_t i = 0; i < n; ++i )
            {
                sum1 += i;
            }
        \end{minted}

        \item Naive reduction, which is even worse than sequential: \begin{minted}{c}
            size_t sum2 = 0;
            size_t local_sum = 0;
            #pragma omp parallel for num_threads( 8 ) private( local_sum )
            for( size_t i = 0; i < n; ++i )
            {
                local_sum = i;

                // This is wrong. It's essentially sequential with a lot of overhead.
                #pragma omp critical
                sum2 += local_sum;
            }
        \end{minted}

        \item Better reduction, which performs slightly \textit{better} than using \mintinline{c}{reduction}: \begin{minted}{c}
            size_t sum3 = 0;
            #pragma omp parallel num_threads( 8 )
            {
                size_t local_sum = 0;
                #pragma omp for
                for(size_t i = 0; i < n; ++i )
                {
                    local_sum += i;
                }

                #pragma omp critical
                sum3 += local_sum;
            }
        \end{minted}
    \end{enumerate}

    All together, with timing code and \mintinline{c}{n = 1000000} we get the following results.

    \begin{minted}{text}
        reduced sum:  499999500000
        elapsed time: 13.664000ms
        naive sum:    499999500000
        elapsed time: 76.582000ms
        critical sum: 499999500000
        elapsed time: 0.291000ms
    \end{minted}

\section{}
    \begin{quote}
        For each of the following code segments, use OpenMP pragmas to make the loop parallel, or explain why the code segment is not suitable for parallel execution.

        \begin{enumerate}
            \item \begin{minted}{c}
                for(i = 0; i < (int) sqrt(x); i++)
                {
                    a[i] = 2.3 * i;
                    if(i < 10)
                        b[i] = a[i];
                }
            \end{minted}

            \item \begin{minted}{c}
                flag = 0;
                for(i = 0; i < n && !flag; i++)
                {
                    a[i] = 2.3 * i;
                    if(a[i] < b[i])
                        flag = 1;
                }
            \end{minted}

            \item \begin{minted}{c}
                for(i = 0; i < n; i++)
                {
                    a[i] = foo(i);
                }
            \end{minted}

            \item \begin{minted}{c}
                for(i = 0; i < n; i++)
                {
                    a[i] = foo(i);
                    if(a[i] > b[i])
                        a[i] = b[i];
                }
            \end{minted}

            \item \begin{minted}{c}
                for(i = 0; i < n; i++)
                {
                    a[i] = foo(i);
                    if(a[i] < b[i])
                        break;
                }
            \end{minted}

            \item \begin{minted}{c}
                dotp = 0;
                for(i = 0; i < n; i++)
                {
                    dotp += a[i] * b[i];
                }
            \end{minted}

            \item \begin{minted}{c}
                for(i = k; i < 2 * k; i++)
                {
                    a[i] = a[i] + a[i-k];
                }
            \end{minted}

            \item \begin{minted}{c}
                for(i = k; i < n; i++)
                {
                    a[i] = b * a[i - k];
                }
            \end{minted}
        \end{enumerate}
    \end{quote}

\section{}
    \begin{quote}
        Given a task that can be divided into $m$ subtasks, each requiring one unit of time, how much time is needed for an $m$-stage pipeline to process $n$ tasks?
    \end{quote}

\section{}
    \begin{quote}
        If the address of the nodes in a hypercube has $n$ bits, at most how many nodes can there be, and how many edges does each node have?

        Give an algorithm that routes a message from node $u$ to node $v$ in this $k$-node hypercube in no more than $\log k$ steps.
    \end{quote}

\section{}
    \begin{quote}
        Research the \textit{shuffle-exchange} network topology. Draw the network with 16 processor nodes (numbering each node in binary, showing shuffle and exchange links). If there are $k$ bits in the address, how many nodes are there? With $n$ nodes, what is the diameter and bisection width of the network? How many edges per node are there?
    \end{quote}

\end{document}
